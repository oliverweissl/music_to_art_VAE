# music_to_art_VAE
Simple variational autoencoder, turning music features to images.
Model was trained on wikiart and DEVKitArt datasets.
WAV files can be used to extract audio features, which will result in an image generated by the decoder.


To use:

- audio_processing, is a notebook dedicateed for feature exploration and visualisation
  --> not necessary for generation of new data

- image_processing, adjusts images in the dataset folders to fit the required size
  --> datasets have to be declared in the LIBS list
  --> datasets only should contain folders containing .jpg images
  
- input_pipeline, generates the dataset for training and contains all modelling parts of the project
  --> the csv for generating images will be generated using audio_data_gen.py in the "Gen new image from audio" block
  --> to load a audio file declare the filename in the audio variable
